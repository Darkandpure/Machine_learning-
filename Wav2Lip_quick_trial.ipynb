{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darkandpure/Machine_learning-/blob/main/Wav2Lip_quick_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# Collab preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73343f8c-9d9b-46b9-e608-a5e189b4a415"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d561cc-fb98-4428-ade5-8150377d8f07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c871787-eccd-4b2f-d0a1-14017bf36873"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 363 (delta 0), reused 1 (delta 0), pack-reused 360\u001b[K\n",
            "Receiving objects: 100% (363/363), 528.20 KiB | 13.21 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd2d003-5967-453c-91cc-28fa7a3e378d"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Wav2Lip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output10.wav  test.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI"
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# Get the pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4934205-4d8e-492f-f513-81f20eaf0ed3"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.12.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "Y\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4af6efc-e860-4b7b-9d78-fe206de63983"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.7.0 (from -r requirements.txt (line 1))\n",
            "  Downloading librosa-0.7.0.tar.gz (1.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.3/1.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.17.1.zip (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a87213-7e6b-4e3f-cc6d-9742a913388f"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 20:20:03--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  17.8MB/s    in 5.5s    \n",
            "\n",
            "2023-07-18 20:20:09 (15.5 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed463340-7cef-4088-814e-50e300b99b29"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/test.mp4\" \"/content/gdrive/My Drive/Wav2Lip/test.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/Wav2Lip/test.wav': No such file or directory\n",
            "anscombe.json\t\t      mnist_test.csv\t     test.mp4\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd9e2c2-7343-4133-9df9-5a627024f260"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test.mp4\" --audio \"../sample_data/test.wav\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   Use more padding to include the chin region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4ad167-2df2-4a0f-8cb3-566aea774bda"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test.mp4\" --audio \"../sample_data/sdfnsdkgnjksdgv.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 84\n",
            "(80, 123)\n",
            "Length of mel chunks: 35\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=11 : invalid argument\n",
            "  0% 0/3 [00:00<?, ?it/s]\n",
            "Recovering from OOM error; New batch size: 8\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 1/5 [00:00<00:02,  1.35it/s]\u001b[A\n",
            " 60% 3/5 [00:00<00:01,  1.83it/s]\u001b[A\n",
            "100% 5/5 [00:01<00:00,  3.17it/s]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 1/1 [00:06<00:00,  6.06s/it]\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '../sample_data/sdfnsdkgnjksdgv.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:01.54, bitrate: 256 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.26.101\n",
            "  Duration: 00:00:01.40, start: 0.000000, bitrate: 387 kb/s\n",
            "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 160x160 [SAR 1:1 DAR 1:1], 360 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mprofile High, level 1.1\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 160x160 [SAR 1:1 DAR 1:1], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=   35 fps=0.0 q=-1.0 Lsize=      37kB time=00:00:01.53 bitrate= 197.0kbits/s speed=17.8x    \n",
            "video:22kB audio:13kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 6.031390%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mframe I:1     Avg QP:24.39  size:  3148\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mframe P:24    Avg QP:25.46  size:   710\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mframe B:10    Avg QP:27.77  size:   177\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mconsecutive B-frames: 57.1%  5.7% 25.7% 11.4%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mmb I  I16..4:  4.0% 68.0% 28.0%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mmb P  I16..4:  0.5%  1.5%  0.1%  P16..4: 44.1% 20.6% 12.7%  0.0%  0.0%    skip:20.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mmb B  I16..4:  0.2%  0.5%  0.0%  B16..8: 46.1%  7.5%  1.2%  direct: 1.1%  skip:43.4%  L0:36.8% L1:43.9% BI:19.2%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0m8x8 transform intra:69.4% inter:62.5%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mcoded y,uvDC,uvAC intra: 74.7% 76.4% 31.8% inter: 24.3% 16.2% 0.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mi16 v,h,dc,p: 41% 24% 29%  6%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 12% 37%  2%  4%  6%  5%  4%  3%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 36% 12% 14%  5%  6% 13%  3%  7%  2%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mi8c dc,h,v,p: 55% 16% 24%  6%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mWeighted P-Frames: Y:4.2% UV:4.2%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mref P L0: 64.0% 22.9%  9.5%  3.6%  0.1%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mref B L0: 93.0%  6.1%  1.0%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mref B L1: 99.4%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609f4494d00] \u001b[0mkb/s:125.51\n",
            "\u001b[1;36m[aac @ 0x5609f449a000] \u001b[0mQavg: 2369.354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}